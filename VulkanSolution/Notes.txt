Layers
	- Layers are features of Vulkan that allow its behavior to be modified. Layers generally intercept all or part of Vulkan and add functionality such as logging, tracing, providing diagnostics, profiling, and so on. A layer can be added at the instance level, in which case it affects the whole Vulkan instance and possibly every device created by it. Alternatively, the layer can be added at the device level, in which case it affects only the device for which it is enabled.



Create Instance -> Choose physical device -> Create logical device -> look queue family


About queue flags
	VK_QUEUE_GRAPHICS_BIT - queues in this family support graphics operations such as drawing points, line,s and triangles.
	VK_QUEUE_COMPUTE_BIT - queues in this family support compute operations such as dispatching compute shaders.
	VK_QUEUE_TRANSFER_BIT - queues in this family support transfer operations such as copying buffer and image contents.
	VK_QUEUE_SPARSE_BINDING_BIT - queues in this family support memory binding operations used to update sparse resources.

About presentation modes:
	VK_PRESENT_MODE_IMMEDIATE_KHR: Images submitted by your application are transferred to the screen right away, which may result in tearing.
	VK_PRESENT_MODE_FIFO_KHR: The swap chain is a queue where the display takes an image from the front of the queue when the display is refreshed and the program inserts rendered images at the back of the queue. If the queue is full then the program has to wait. This is most similar to vertical sync as found in modern games. The moment that the display is refreshed is known as "vertical blank".	
	VK_PRESENT_MODE_FIFO_RELAXED_KHR: This mode only differs from the previous one if the application is late and the queue was empty at the last vertical blank. Instead of waiting for the next vertical blank, the image is transferred right away when it finally arrives. This may result in visible tearing.
	VK_PRESENT_MODE_MAILBOX_KHR: This is another variation of the second mode. Instead of blocking the application when the queue is full, the images that are already queued are simply replaced with the newer ones. This mode can be used to render frames as fast as possible while still avoiding tearing, resulting in fewer latency issues than standard vertical sync. This is commonly known as "triple buffering", although the existence of three buffers alone does not necessarily mean that the framerate is unlocked.

VkSwapchainCreateInfoKHR:
	createInfo.imageUsage:
		This specifies what kind of operations we'll use the images in the swap chain for.
		We use COLOR_ATTACHMENT_BIT to render directly to it.
		If you want to render images to a separate image first to perform operations like post-processing.
		It might be TRANSFER_DST_BIT

	There are a lot of flags:
		VK_IMAGE_USAGE_SAMPLED_BIT
		VK_IMAGE_USAGE_STORAGE_BIT
		VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT
		VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT
		VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT
		VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT
		VK_IMAGE_USAGE_FRAGMENT_SHADING_RATE_ATTACHMENT_BIT_KHR
		VK_IMAGE_USAGE_FRAGMENT_DENSITY_MAP_BIT_EXT
		VK_IMAGE_USAGE_VIDEO_DECODE_DST_BIT_KHR
		VK_IMAGE_USAGE_VIDEO_DECODE_DPB_BIT_KHR
		VK_IMAGE_USAGE_VIDEO_ENCODE_SRC_BIT_KHR
		VK_IMAGE_USAGE_VIDEO_ENCODE_DPB_BIT_KHR
		VK_IMAGE_USAGE_SAMPLE_WEIGHT_BIT_QCOM
		VK_IMAGE_USAGE_SAMPLE_BLOCK_MATCH_BIT_QCOM

Creating Graphics Pipeline:
	ShaderStages
	DynamicState
	VertexInputState
	InputAssemblyState
	ViewportState
	RasterizationState
	MultisampleState
	DepthStencilState
	ColorBlending(two methods):
		ColorBlendAttachmentState
		ColorBlendState
	PipelineLayout

RenderPass:
	VkAttachment loadOp:
		VK_ATTACHMENT_LOAD_OP_LOAD: Preverse the existing contents of the attachment
		VK_ATTACHMENT_LOAD_OP_CLEAR: Clear the values to a constant at the start
		VK_ATTACHMENT_LOAD_OP_DONT_CARE: Existing contents are undefined; we don't care about them
	VkAttachment storeOp:
		VK_ATTACHMENT_STORE_OP_STORE: Rendered contents will be stored in memory and can be read later
		VK_ATTACHMENT_STORE_OP_DONT_CARE: Contents of the framebuffer will be undefined after the rendering operation

VkAttachmentReference:
	ref.layout:
		The layout specifies which layout we would like the attachment to have during a subpass that uses this reference.
		Vulkan will automatically transition the attachment to this layout when the subpass is started.

Pipeline recaps:
	Shader stages:
		The shader modules that define the functionality of the programmable stages of the graphics pipeline
	Fixed-function state:
		All of the structures that define the fixed-function stages of the pipeline, like input assembly, rasterizer, viewport and color blending
	Pipeline layout: 
		The uniform and push values referenced by the shader that can be updated at draw time
	Render pass:
		The attachments referneced by the pipeline stages and their usage


vkCmdBeginRenderPass flag:
	VK_SUBPASS_CONTENTS_INLINE: The render pass commands will be embedded in the primary command buffer itself and no secondary command buffers will be executed.
	Vk_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS: The render pass commands will be executed from secondary command buffers.

Outline of a frame:
	At a high level, rendering a frame in Vulkan consists of a common set of steps:
		Wait for the previous frame to finish
		Acquire an image from the swap chain
		Record a command buffer which draws the scene onto that image
		Submit the recorded command buffer
		Present the swap chain image

Synchronization:
	Important steps to draw something to a screen such as...
		Acquire an image from the swap chain
		Execute commands that draws onto the acquired image
		Present that image to the screen for presentaion, returning it to the swapchain
	Need synchronization with GPU.
	Methods to synchronize it with GPU:
		Semaphores (Block GPU side):
			It is used to add order between queue operations.
			There are binary semaphores and timeline semaphores.
			How semephores work:
				A semaphore is either unsignaled or signaled. 
				It begins life as unsignaled. 
				The way we use a semaphore to order queue operations is by providing the same semaphore as a 'signal' semaphore in one queue operation and as a 'wait' semaphore in another queue operation.

				For example,
					Lets say we have semaphore S and queue operations A and B that we want to execute in order.
					What we tell Vulkan is that operation A will 'signal' semaphore S when it finishes executing, and operation B will 'wait' on semaphore S before it begins executing.
					When operation A finishes, semaphore S will be signaled, while operation B wont start until S is signaled.
					After operation B begins executing, semaphore S is automatically reset back to being unsignaled, allowing it to be used again.


		Fences (Block CPU side):
			Usage: If the CPU needs to know when the GPU has finished something, we use a fence.
			How fences work:
				Similar to semaphores, fences are either in a signaled or unsignaled state.
				Whenever we submit work to execute, we can attach a fence to that work. 
				When the work is finished, the fence will be signaled.
				Then we can make the host wait for the fence to be signaled, guaranteeing that the work has finished before the host continues.

		What to choose?
			Generally, stop CPU is not preferred.
			Using semaphores for swapchain operations
			Using fences for waiting on the previous frame to finish



What is Subpass dependency????


VkVertexInputAttributeDescription format examples:
	float: VK_FORMAT_R32_SFLOAT
	vec2: VK_FORMAT_R32G32_SFLOAT
	vec3: VK_FORMAT_R32G32B32_SFLOAT
	vec4: VK_FORMAT_R32G32B32A32_SFLOAT
	ivec2: VK_FORMAT_R32G32_SINT
	uvec4: VK_FORMAT_R32G32B32A32_UINT
	double: VK_FORMAT_R64_SFLOAT

vkMapMemory & vkUnmapMemory issue:
	Unfortunately the driver may not immediately copy the data into the buffer memory, for example because of caching.
	It is also possible that writes to the buffer are not visible in the mapped memory yet.
	There are two ways to deal with that problem:
		Use a memory heap that is host coherent, indicated with VK_MEMORY_PROPERTY_HOST_COHERENT_BIT
		Call vkFlushMappedMemoryRanges after writing to the mapped memory, and call vkInvalidateMappedMemoryRanges before reading from the mapped memory

	First approach may lead to slightly worse performance than explicit flushing which is the second method.



Quest!'
@If you like a challenge, then you can still try to use a different queue family specifically for transfer operations. It will require you to make the following modifications to your program:

@1. Modify QueueFamilyIndices and findQueueFamilies to explicitly look for a queue family with the VK_QUEUE_TRANSFER_BIT bit, but not the VK_QUEUE_GRAPHICS_BIT.
@2. Modify createLogicalDevice to request a handle to the transfer queue
@3. Create a second command pool for command buffers that are submitted on the transfer queue family
@4. Change the sharingMode of resources to be VK_SHARING_MODE_CONCURRENT and specify both the graphics and transfer queue families
@5. Submit any transfer commands like vkCmdCopyBuffer (which we'll be using in this chapter) to the transfer queue instead of the graphics queue

It's a bit of work, but it'll teach you a lot about how resources are shared between queue families.



!@!@!@!@!@vkAllocateMemory WARNINGS@!@!@!@!@!@!@:
It should be noted that in a real world application, you're not supposed to actually call vkAllocateMemory for every individual buffer. 
The maximum number of simultaneous memory allocations is limited by the maxMemoryAllocationCount physical device limit(4096 even on NVIDIA GTX 1080). 
	Two solutions:
		1. Create a custom allocator that splits up a single allocation among many different objects by using the offset parameters that we've seen in many functions.
		2. Use the VulkanMemoryAllocator library provided by the GPUOpen initiative. 

Driver developers recommend that you also store multiple buffers, like the vertex and index buffer, into a single VkBuffer and use offsets in commands like vkCmdBindVertexBuffers. 
The advantage is that your data is more cache friendly in that case, because it's closer together.